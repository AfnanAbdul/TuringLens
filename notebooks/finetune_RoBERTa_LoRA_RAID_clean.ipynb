{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfnanAbdul/TuringLens/blob/main/notebooks/finetune_RoBERTa_LoRA_RAID_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0l6JfmpyAiAo",
        "outputId": "a22f820c-fd26-484f-88e3-9b1d21a473b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gR3wNP3o9FI"
      },
      "source": [
        "# Fine-tuning RoBERTa-LoRA for AI Text Detection on RAID Abstracts Dataset\n",
        "\n",
        "In this notebook, we further fine-tune a RoBERTa model with Low-Rank Adaptation (LoRA) that was initially trained on the Kaggle LLM-generated text detection dataset (`finetune_roberta_lora.ipynb`). We now adapt this pre-trained model specifically for academic abstracts using the RAID (Robust AI-generated text Detection) dataset.\n",
        "\n",
        "## Key Challenges Addressed\n",
        "Our evaluation of the initial model on an external dataset (RAID abstract domain) revealed a significant bias in predictions: while it excelled at detecting AI-generated text (97.3% accuracy), it struggled with correctly identifying human-written text (16.8% accuracy). This is a common challenge in AI detection systems due to dataset imbalances and the increasing sophistication of AI text generators.\n",
        "\n",
        "## Improvements\n",
        "We implement several strategies to address this classification bias:\n",
        "\n",
        "1. **Balanced Dataset Construction**: Created a balanced dataset with equal representation of human texts, regular AI-generated texts, and adversarial AI examples (1,766 samples of each category).\n",
        "\n",
        "2. **Aggressive Class Weighting**: Applied a 10:1 weighting ratio (5.0 for human class, 0.5 for AI class) to heavily penalize the model for misclassifying human text as AI-generated.\n",
        "\n",
        "3. **Human-Focused Evaluation Metrics**: Added specific metrics to track human text detection performance:\n",
        "   - `human_accuracy`: Measures success rate on human texts\n",
        "   - `human_false_positive_rate`: Tracks how often human text is wrongly labeled as AI\n",
        "   - `balanced_accuracy`: Provides a fairer assessment across both classes\n",
        "\n",
        "4. **Optimized Training Configuration**:\n",
        "   - Set `human_accuracy` as the primary metric to optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHjc1_OdC4SV",
        "outputId": "c3efac36-c794-4eb9-f7a8-4a8077ece0f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7Om1ydI_-YH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfO_O14TAnX0",
        "outputId": "e4c47f0d-29ec-4838-d9fa-3f4377737f21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5b23286970>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDhcqNbtDwSa",
        "outputId": "f2bebae8-c78c-46c0-972a-47cb5e7a3f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: Tesla T4\n",
            "Number of GPUs: 1\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU available, using CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J075jIi6AsI3"
      },
      "source": [
        "## Loading the RAID dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380,
          "referenced_widgets": [
            "ec308d9547174ee2a19c85707ff31d91",
            "57f17d6489e846f3ab57efbf1f9d4b5e",
            "e20cdd1acb3b4b53837983f4644ca64e",
            "1bbf672cb50545ec9f3d904614c643b9",
            "8ef7b4acde4945f392182ee3fa335985",
            "1d70e5013f804d4c982c5f4b5d381045",
            "280f82e7d3fb46c8b29400fc9708a55e",
            "8061a868fc7241cd8019bd911669bfc3",
            "2af928780c3a454880cce659db958adb",
            "3d402c6eb74840c38c454c7ad760e563",
            "14125222298e4d49a3f0b0e6c30395ab",
            "16743c7c069243bb934cdd339c657246",
            "36fd7314227f4413b7b58a327f5bf79f",
            "e73fcc94645547f7bf32553b9fba9d33",
            "d97b52e4b6424a01bdf5a88006225b0c",
            "220efd71206e4fb5af9a0ae7bc11ebc0",
            "c4572825509f45eaa7fd7864482d736d",
            "d62ef4a8647a4a9699cf251661934b1b",
            "b294af1edb7846fe9c40aad50ba08af5",
            "c0fdfd782e83490898d44097bb04636a",
            "ad2cfa66af144acabd6d7841d89c3a73",
            "226154dc231c4ee894d05bd0c8109eb9",
            "32cb053abe794485a085f7d9d9541c39",
            "fe7f4295d78345b3b1d431d3e559df1c",
            "7b419b36d3484ca3a3ff1b7160ff9699",
            "204246833d0e4ef4bb19fb02e383b2fd",
            "62a1fe8f335e4d4ab91579d4c53dd7e7",
            "872197e8e82c4dd5a1e96b6832302be2",
            "683f2586998b4a288a97f71f0c782c72",
            "e369b005f5cf470994098704939a9d8e",
            "b49add7d4acc4442a84866d3618f40ab",
            "8dac68b6348c44f18ec14ce972e19321",
            "df4bb01159264ee2b2dd7f8019d7b8cc",
            "3f1e1431e77547258ce859550b8baeab",
            "2b80fadbf0ec4d4da0a7382b74d92317",
            "61ee3b2b933e4555a03edfcc0d218e11",
            "dd95f344a60e4f239d53a071de374ae0",
            "fe7dfea8a9ed40abbded470df98cfde6",
            "a8f177b6e5d4448494ba9ac7b06c1e60",
            "0be3651ddcc8400693b2f440ead339f2",
            "532dd504dc614c318007864bd3dbde6e",
            "5caf50b07bd64ec8afe71e99cca9b5e7",
            "98b172a924c94f10aeea5e55edcd09c6",
            "586e70d530854a81b62725583777ec31",
            "e5233b467f6444dea00fe386dc33f3f9",
            "2b08ecd62f884d669d9ef384617d65be",
            "d054378bd565403fbe0661e8d4e021c6",
            "885ec01522974561bd92416de8dc4b78",
            "370065a9bbf24627829a637f927b79d1",
            "cda3947404e8480983129fb3bf1fab6a",
            "cc132418339c4f93a4cf38f8fbd434fd",
            "67d16908ad30452ab5a5aa7b041425b3",
            "cf29cff5e872494fa8bc92405d620081",
            "2387c3e2eed74bdfa72464bca7ee6b41",
            "55ca21734117479ca2a05893ed10318e",
            "b55fe42935e94924b8768ffac1e0b44b",
            "af23769c7ec3408a85c7e0e1256befa5",
            "ff3182bebe7c4807a24db078f17bcf80",
            "316d4c3efedd4a6eb01499ae1bc23aae",
            "3aa035fb6f0d4f4baf69ad1a5df5d0ef",
            "bb8c784051b64f8da68f1346378e77e4",
            "18239eaa5f0247f7819ef383d0998383",
            "dfd057ba2d46425684d840e78f496d63",
            "bb048475dac9448f9ad26a7d881cd377",
            "2bce2c63c38d44f89314836d6d963b65",
            "028def0593974f43a85b602ab17dbf2f",
            "a84f8402f6a74467a03778cb3a9acd42",
            "2c07bf7ac0454e16b5a5cdcedb0af8ed",
            "d39643eb5dd240479fe49d57cfb7a04a",
            "0c40b30077a04a4e8b0a129ffa27b413",
            "30f623c0372b4f1da76bd356e81f8936",
            "f3fa2668a0864f4b9fbd9903a845ca22",
            "3eaf5e4cdff64d98a4706dfe5e3008c8",
            "faf7e3082b7c463cb4962893df001d1a",
            "209c809bdc8045fea5b2a64b6ce7fbf4",
            "570fb8e95c31475ba259f52e40ebe44e",
            "eef48262ab324111806054bcda564616"
          ]
        },
        "id": "iF6pIbAAAwG7",
        "outputId": "3261cce7-c38d-452f-a489-70578fef6dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading RAID abstract domain...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec308d9547174ee2a19c85707ff31d91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/3.66k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16743c7c069243bb934cdd339c657246",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train.csv:   0%|          | 0.00/11.8G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "32cb053abe794485a085f7d9d9541c39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "extra.csv:   0%|          | 0.00/3.71G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f1e1431e77547258ce859550b8baeab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5233b467f6444dea00fe386dc33f3f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating extra split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b55fe42935e94924b8768ffac1e0b44b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading dataset shards:   0%|          | 0/24 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a84f8402f6a74467a03778cb3a9acd42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/5615820 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load only the abstract domain data\n",
        "print(\"Loading RAID abstract domain...\")\n",
        "raid = load_dataset(\"liamdugan/raid\", split=\"train\").filter(lambda x: x[\"domain\"] == \"abstracts\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0ou2iZME03y"
      },
      "source": [
        "## Pre-processing & splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N66Nf2D5A10k",
        "outputId": "e5bf20b6-93a4-4290-d557-415da522b03a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total abstract examples: 741720\n"
          ]
        }
      ],
      "source": [
        "abstracts_df = raid.to_pandas()\n",
        "print(f\"Total abstract examples: {len(abstracts_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsWDampQcYae"
      },
      "source": [
        "convert into a binary classification problem:\n",
        "\n",
        "\n",
        "*   Label 0: Human-written content\n",
        "*   Label 1: AI-generated content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aid-aJpfMatg"
      },
      "outputs": [],
      "source": [
        "# Create a binary label (0 for human, 1 for AI)\n",
        "abstracts_df['label'] = abstracts_df['model'].apply(lambda x: 0 if x == 'human' else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "SMmqBOEgMefr",
        "outputId": "2265e40e-48db-47ec-97b2-26015620f491"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "abstracts_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-75180d25-3664-4241-a831-66b425c9f6f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>adv_source_id</th>\n",
              "      <th>source_id</th>\n",
              "      <th>model</th>\n",
              "      <th>decoding</th>\n",
              "      <th>repetition_penalty</th>\n",
              "      <th>attack</th>\n",
              "      <th>domain</th>\n",
              "      <th>title</th>\n",
              "      <th>prompt</th>\n",
              "      <th>generation</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
              "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
              "      <td>e5e058ce-be2b-459d-af36-32532aaba5ff</td>\n",
              "      <td>human</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>none</td>\n",
              "      <td>abstracts</td>\n",
              "      <td>FUTURE-AI: Guiding Principles and Consensus Re...</td>\n",
              "      <td>None</td>\n",
              "      <td>The recent advancements in artificial intellig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
              "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
              "      <td>f95b107b-d176-4af5-90f7-4d0bb20caf93</td>\n",
              "      <td>human</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>none</td>\n",
              "      <td>abstracts</td>\n",
              "      <td>EdgeFlow: Achieving Practical Interactive Segm...</td>\n",
              "      <td>None</td>\n",
              "      <td>High-quality training data play a key role in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
              "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
              "      <td>856d8972-9e3d-4544-babc-0fe16f21e04d</td>\n",
              "      <td>human</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>none</td>\n",
              "      <td>abstracts</td>\n",
              "      <td>Semi-supervised Contrastive Learning for Label...</td>\n",
              "      <td>None</td>\n",
              "      <td>The success of deep learning methods in medica...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
              "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
              "      <td>fbc8a5ea-90fa-47b8-8fa7-73dd954f1524</td>\n",
              "      <td>human</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>none</td>\n",
              "      <td>abstracts</td>\n",
              "      <td>Combo Loss: Handling Input and Output Imbalanc...</td>\n",
              "      <td>None</td>\n",
              "      <td>Simultaneous segmentation of multiple organs f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
              "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
              "      <td>72c41b8d-0069-4886-b734-a4000ffca286</td>\n",
              "      <td>human</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>none</td>\n",
              "      <td>abstracts</td>\n",
              "      <td>Attention-Based 3D Seismic Fault Segmentation ...</td>\n",
              "      <td>None</td>\n",
              "      <td>Detection faults in seismic data is a crucial ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75180d25-3664-4241-a831-66b425c9f6f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75180d25-3664-4241-a831-66b425c9f6f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75180d25-3664-4241-a831-66b425c9f6f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80ed40b4-d55e-46d1-8955-14cd2db6bbcb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80ed40b4-d55e-46d1-8955-14cd2db6bbcb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80ed40b4-d55e-46d1-8955-14cd2db6bbcb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                     id                         adv_source_id  \\\n",
              "0  e5e058ce-be2b-459d-af36-32532aaba5ff  e5e058ce-be2b-459d-af36-32532aaba5ff   \n",
              "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  f95b107b-d176-4af5-90f7-4d0bb20caf93   \n",
              "2  856d8972-9e3d-4544-babc-0fe16f21e04d  856d8972-9e3d-4544-babc-0fe16f21e04d   \n",
              "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524   \n",
              "4  72c41b8d-0069-4886-b734-a4000ffca286  72c41b8d-0069-4886-b734-a4000ffca286   \n",
              "\n",
              "                              source_id  model decoding repetition_penalty  \\\n",
              "0  e5e058ce-be2b-459d-af36-32532aaba5ff  human     None               None   \n",
              "1  f95b107b-d176-4af5-90f7-4d0bb20caf93  human     None               None   \n",
              "2  856d8972-9e3d-4544-babc-0fe16f21e04d  human     None               None   \n",
              "3  fbc8a5ea-90fa-47b8-8fa7-73dd954f1524  human     None               None   \n",
              "4  72c41b8d-0069-4886-b734-a4000ffca286  human     None               None   \n",
              "\n",
              "  attack     domain                                              title prompt  \\\n",
              "0   none  abstracts  FUTURE-AI: Guiding Principles and Consensus Re...   None   \n",
              "1   none  abstracts  EdgeFlow: Achieving Practical Interactive Segm...   None   \n",
              "2   none  abstracts  Semi-supervised Contrastive Learning for Label...   None   \n",
              "3   none  abstracts  Combo Loss: Handling Input and Output Imbalanc...   None   \n",
              "4   none  abstracts  Attention-Based 3D Seismic Fault Segmentation ...   None   \n",
              "\n",
              "                                          generation  label  \n",
              "0  The recent advancements in artificial intellig...      0  \n",
              "1  High-quality training data play a key role in ...      0  \n",
              "2  The success of deep learning methods in medica...      0  \n",
              "3  Simultaneous segmentation of multiple organs f...      0  \n",
              "4  Detection faults in seismic data is a crucial ...      0  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "abstracts_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLVlRaFPclnK"
      },
      "source": [
        "The dataset contains both regular and adversarial examples:\n",
        "\n",
        "\n",
        "*   Regular examples are standard human or AI-generated text\n",
        "*   Adversarial examples are AI-generated texts designed to be harder to detect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atw7W-kSA9g9"
      },
      "outputs": [],
      "source": [
        "# Split by adversarial/non-adversarial\n",
        "regular_abstracts = abstracts_df[abstracts_df['attack'] == 'none']\n",
        "adversarial_abstracts = abstracts_df[abstracts_df['attack'] != 'none']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvVrkU7NBDOy",
        "outputId": "39cb4037-e0d2-4990-e1f8-ff5345cd9de5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Regular abstracts: 61810\n",
            "Adversarial abstracts: 679910\n",
            "Human examples in regular abstracts: 1766\n",
            "AI examples in regular abstracts: 60044\n"
          ]
        }
      ],
      "source": [
        "print(f\"Regular abstracts: {len(regular_abstracts)}\")\n",
        "print(f\"Adversarial abstracts: {len(adversarial_abstracts)}\")\n",
        "print(f\"Human examples in regular abstracts: {len(regular_abstracts[regular_abstracts['model'] == 'human'])}\")\n",
        "print(f\"AI examples in regular abstracts: {len(regular_abstracts[regular_abstracts['model'] != 'human'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CznBV5sCcvHM"
      },
      "source": [
        "The data is split into train/validation/test sets (70/15/15 split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29SGhxbHBO0o"
      },
      "outputs": [],
      "source": [
        "# Split the data into train, validation, and test sets (70/15/15 split)\n",
        "# First, separate into regular and adversarial sets\n",
        "regular_human = regular_abstracts[regular_abstracts['model'] == 'human']\n",
        "regular_ai = regular_abstracts[regular_abstracts['model'] != 'human']\n",
        "\n",
        "# Split regular examples into train, validation, and test\n",
        "# Human data\n",
        "# train_human, temp_human = train_test_split(regular_human, test_size=0.3, random_state=42)\n",
        "# val_human, test_human = train_test_split(temp_human, test_size=0.5, random_state=42)\n",
        "\n",
        "# AI data (regular)\n",
        "# train_ai, temp_ai = train_test_split(regular_ai, test_size=0.3, random_state=42)\n",
        "# val_ai, test_ai = train_test_split(temp_ai, test_size=0.5, random_state=42)\n",
        "\n",
        "# Split adversarial examples (only for AI) similar to regular AI examples\n",
        "# adv_train, adv_temp = train_test_split(adversarial_abstracts, test_size=0.3, random_state=42)\n",
        "# adv_val, adv_test = train_test_split(adv_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Combine the splits\n",
        "# train_df = pd.concat([train_human, train_ai, adv_train])\n",
        "# val_df = pd.concat([val_human, val_ai, adv_val])\n",
        "# test_df = pd.concat([test_human, test_ai, adv_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzsoLVRqfvzs"
      },
      "source": [
        "Using a sample of the dataset (1,766 human + 1,766 regular AI + 1,766 adversarial AI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFfJaLNJfKdL"
      },
      "outputs": [],
      "source": [
        "sample_size_regular_human = 1766  # Number of human examples\n",
        "sample_size_regular_ai = 1766     # Number of AI examples (regular)\n",
        "sample_size_adversarial = 1766    # Number of adversarial examples\n",
        "\n",
        "# Sample regular human abstracts\n",
        "sampled_regular_human = regular_human.sample(n=min(sample_size_regular_human, len(regular_human)), random_state=42)\n",
        "\n",
        "# Sample regular AI abstracts\n",
        "sampled_regular_ai = regular_ai.sample(n=min(sample_size_regular_ai, len(regular_ai)), random_state=42)\n",
        "\n",
        "# Sample adversarial abstracts\n",
        "sampled_adversarial = adversarial_abstracts.sample(n=min(sample_size_adversarial, len(adversarial_abstracts)), random_state=42)\n",
        "\n",
        "# Now split these sampled datasets into train/val/test\n",
        "# Human data\n",
        "train_human, temp_human = train_test_split(sampled_regular_human, test_size=0.3, random_state=42)\n",
        "val_human, test_human = train_test_split(temp_human, test_size=0.5, random_state=42)\n",
        "\n",
        "# AI data (regular)\n",
        "train_ai, temp_ai = train_test_split(sampled_regular_ai, test_size=0.3, random_state=42)\n",
        "val_ai, test_ai = train_test_split(temp_ai, test_size=0.5, random_state=42)\n",
        "\n",
        "# Adversarial examples\n",
        "adv_train, adv_temp = train_test_split(sampled_adversarial, test_size=0.3, random_state=42)\n",
        "adv_val, adv_test = train_test_split(adv_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Combine the splits\n",
        "train_df = pd.concat([train_human, train_ai, adv_train])\n",
        "val_df = pd.concat([val_human, val_ai, adv_val])\n",
        "test_df = pd.concat([test_human, test_ai, adv_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cz0dbV3BdYy",
        "outputId": "42a512da-6f9c-4a69-e15a-fe5fe23f8ff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: 3708 samples\n",
            "Validation set: 795 samples\n",
            "Test set: 795 samples\n"
          ]
        }
      ],
      "source": [
        "# Shuffle each split\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "val_df = val_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Print split sizes\n",
        "print(f\"\\nTrain set: {len(train_df)} samples\")\n",
        "print(f\"Validation set: {len(val_df)} samples\")\n",
        "print(f\"Test set: {len(test_df)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS-QiKDTBgLk",
        "outputId": "f29f7a6f-bfb2-4205-b620-96ab50eefc87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set label distribution:\n",
            "label\n",
            "1    2428\n",
            "0    1280\n",
            "Name: count, dtype: int64\n",
            "Validation set label distribution:\n",
            "label\n",
            "1    521\n",
            "0    274\n",
            "Name: count, dtype: int64\n",
            "Test set label distribution:\n",
            "label\n",
            "1    525\n",
            "0    270\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Print label distribution in each split\n",
        "print(f\"\\nTrain set label distribution:\\n{train_df['label'].value_counts()}\")\n",
        "print(f\"Validation set label distribution:\\n{val_df['label'].value_counts()}\")\n",
        "print(f\"Test set label distribution:\\n{test_df['label'].value_counts()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjkd4SZePoBb"
      },
      "source": [
        "There are many more AI-generated texts (label 1) than human-written texts (label 0)\n",
        "\n",
        "Adding a higher weight to the human class to penalize misclassifications more heavily ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97gTUHBzNfBq",
        "outputId": "b4955fcb-4d85-454b-c2cd-5eb2db55ff65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: {0: 5.0, 1: 0.5}\n"
          ]
        }
      ],
      "source": [
        "human_weight = 5.0  # Significantly higher weight for human class (was ~1.44)\n",
        "ai_weight = 0.5     # Lower weight for AI class (was ~0.76)\n",
        "\n",
        "weights_dict = {0: human_weight, 1: ai_weight}\n",
        "print(f\"Class weights: {weights_dict}\")\n",
        "\n",
        "# Keep the rest the same\n",
        "class_weights_tensor = torch.FloatTensor([weights_dict[0], weights_dict[1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJvNTbH7BiwX"
      },
      "source": [
        "## Load our previously finetuned RoBERTa LoRA model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK9XQKzqBuVf",
        "outputId": "88946b27-ff54-484d-faf7-75b4a22d51b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading pre-trained RoBERTa-LoRA model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained model and tokenizer\n",
        "print(\"\\nLoading pre-trained RoBERTa-LoRA model...\")\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-ai-detector\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNKs19JTB0ur"
      },
      "outputs": [],
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wOD7i2LB1d5"
      },
      "outputs": [],
      "source": [
        "def preprocess(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"generation\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "dc2407c9d6794b06a340081c1a3fa06a",
            "a1db21f0e0874abb8b94b97f3ad4bb64",
            "0fc42f50b79549eda4c85026fd0eb5b7",
            "afccffd7beac4d499abc8e92dfae4915",
            "26698156f1c84b7782be6300422bba90",
            "908a4fadcbbd4580afb7d4df47b8cce2",
            "7ac80ebf12ea4ef6b37480432289be25",
            "67a355f27565439793e058399b023c72",
            "dc54b270e2e6438e895e078a0cdc65e4",
            "14b616106e6746b1b62facfe0f13fe08",
            "6deb3f641d684bdb84747dd9b3ce3c91",
            "0d416124732e40919d457efc61364ed9",
            "98035a3243034e829899e0f4e2aa7343",
            "6014f7af502b48ccba10af3c9725bc1c",
            "4f1a26081e38400fa92a37982be89813",
            "2839400b8d654d47b84dc9406f8f9f30",
            "98a017829034439cb7e2acf4340ec395",
            "561cff71e6ac442bbf4a5bc7ffc5e71a",
            "06d9dd99d5194ea6b6f301908b4ba89e",
            "464ad4a0a438472ba8e5f977586865a4",
            "f0248b687668438ea7cad3d756328753",
            "970a6a55c89f4d36be757110e3745097",
            "6059964d3d604feaa0ccb20a185d65c7",
            "af6aeb494fd5444db4f3856c8edb8c46",
            "0c487ae75e9744da8ac24a8406931c9b",
            "936aa378c6b34896a2f1827382c1e22c",
            "9251ce69b8c041bcb55eeda4fae9bab8",
            "8afc9940d0fd41bca7b8fc83765552fb",
            "863e5bfb816f47aa878695578facf2da",
            "aacff73b654f4ecb826dfb111c4ed8a3",
            "c75a6d03330349158c5992ae667cf410",
            "b9b11cd6cc6d4ce2a02348fafe48e166",
            "6c4b20b95f40403fa7e431f2cadcf69b"
          ]
        },
        "id": "RTlr6SWLB6nj",
        "outputId": "1b71c034-bf34-4523-9dfd-477778b7b740"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dc2407c9d6794b06a340081c1a3fa06a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3708 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d416124732e40919d457efc61364ed9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/795 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6059964d3d604feaa0ccb20a185d65c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/795 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_train = train_dataset.map(preprocess, batched=True)\n",
        "tokenized_val = val_dataset.map(preprocess, batched=True)\n",
        "tokenized_test = test_dataset.map(preprocess, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jrRaRr2Y78J"
      },
      "outputs": [],
      "source": [
        "class WeightedLoss:\n",
        "    def __init__(self, class_weights):\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def __call__(self, logits, labels):\n",
        "        # Move weights to same device as logits\n",
        "        if self.class_weights.device != logits.device:\n",
        "            self.class_weights = self.class_weights.to(logits.device)\n",
        "\n",
        "        # Use CrossEntropyLoss with weights\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "        return loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTPKsag2CAUt"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Overall metrics\n",
        "    metrics = {}\n",
        "    metrics[\"accuracy\"] = accuracy_score(labels, predictions)\n",
        "    metrics[\"precision\"] = precision_score(labels, predictions)\n",
        "    metrics[\"recall\"] = recall_score(labels, predictions)\n",
        "    metrics[\"f1\"] = f1_score(labels, predictions)\n",
        "\n",
        "    # Class-specific metrics\n",
        "    human_indices = np.where(labels == 0)[0]\n",
        "    ai_indices = np.where(labels == 1)[0]\n",
        "\n",
        "    # Add human_false_positive_rate\n",
        "    if len(human_indices) > 0:\n",
        "        human_preds = predictions[human_indices]\n",
        "        metrics[\"human_accuracy\"] = np.mean(human_preds == 0)\n",
        "        metrics[\"human_false_positive_rate\"] = np.mean(human_preds == 1)\n",
        "\n",
        "    # Add AI detection accuracy\n",
        "    if len(ai_indices) > 0:\n",
        "        ai_preds = predictions[ai_indices]\n",
        "        metrics[\"ai_accuracy\"] = np.mean(ai_preds == 1)\n",
        "\n",
        "    # Calculate balanced accuracy\n",
        "    metrics[\"balanced_accuracy\"] = (metrics.get(\"human_accuracy\", 0) + metrics.get(\"ai_accuracy\", 0)) / 2\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SabrlvYuUeZZ",
        "outputId": "7a383a39-473a-491b-a134-b813b53e4377"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/i1uzq8x8?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f56ee40ead0>"
            ]
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUgTu4lXhGJE"
      },
      "outputs": [],
      "source": [
        "# Make sure the model is in training mode\n",
        "model.train()\n",
        "\n",
        "# Explicitly enable gradients for all model parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Make sure your class weights tensor has requires_grad set to False\n",
        "class_weights_tensor = torch.FloatTensor([weights_dict[0], weights_dict[1]]).to(device)\n",
        "class_weights_tensor.requires_grad = False  # We don't need gradients for the weights themselves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10ObNjiCmDbk",
        "outputId": "b1667960-370c-4cea-8a3f-c44bc4534abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory exists: True\n"
          ]
        }
      ],
      "source": [
        "output_dir = \"/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Directory exists: {os.path.exists(output_dir)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy1j4B5QCFn6",
        "outputId": "fa8e3f35-413d-45a5-af09-e41101130148"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"human_accuracy\",  # Focus on human accuracy\n",
        "    greater_is_better=True,\n",
        "    push_to_hub=False,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    seed=42,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    warmup_steps=500,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    report_to=[],\n",
        "    save_safetensors=True  # Use the safer format for saving\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZsd4544ZWWf"
      },
      "outputs": [],
      "source": [
        "# Define a custom Trainer class with weighted loss\n",
        "class WeightedLossTrainer(Trainer):\n",
        "    def __init__(self, class_weights=None, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # Added **kwargs to catch any additional arguments like num_items_in_batch\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "\n",
        "        # Apply weights to loss\n",
        "        if self.class_weights is not None:\n",
        "            if self.class_weights.device != logits.device:\n",
        "                self.class_weights = self.class_weights.to(logits.device)\n",
        "\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mje9R_g_bmXO"
      },
      "outputs": [],
      "source": [
        "from accelerate import Accelerator\n",
        "accelerator = Accelerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrrLXJILCMgw",
        "outputId": "d72cfd0c-478f-43b5-d0e6-d38ecf4c7779"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-205-8b37c9dd5110>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedLossTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary for early stopping\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import TrainerCallback\n",
        "\n",
        "class SaveCallback(TrainerCallback):\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        if state.global_step % 10000 == 0:  # Save every 10,000 steps\n",
        "            control.should_save = True\n",
        "            return control\n",
        "\n",
        "# Initialize Trainer with weighted loss\n",
        "trainer = WeightedLossTrainer(\n",
        "    class_weights=class_weights_tensor,\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxfHTpt-Cgvc"
      },
      "source": [
        "## Fine-tune the model\n",
        "Further fine-tuning the existing LoRA weights on this new, domain-specific dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "n42hGaHdT1fJ",
        "outputId": "61e929d7-1468-4c39-e78d-3d4a3d903e39"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "function ConnectButton(){\n",
              "    console.log(\"Clicking Connect Button\");\n",
              "    document.querySelector(\"colab-connect-button\").click()\n",
              "}\n",
              "setInterval(ConnectButton, 60000);\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import IPython\n",
        "from IPython.display import Javascript\n",
        "\n",
        "display(Javascript('''\n",
        "function ConnectButton(){\n",
        "    console.log(\"Clicking Connect Button\");\n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ConnectButton, 60000);\n",
        "'''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "oE4AwLUECQmG",
        "outputId": "a37981b5-db81-4377-9cdc-517cb681cda6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting fine-tuning...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2321' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2320/2320 21:35, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Human Accuracy</th>\n",
              "      <th>Human False Positive Rate</th>\n",
              "      <th>Ai Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.074109</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.996146</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.992512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.117700</td>\n",
              "      <td>0.083082</td>\n",
              "      <td>0.991195</td>\n",
              "      <td>0.996139</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.993263</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.991552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.075300</td>\n",
              "      <td>0.049584</td>\n",
              "      <td>0.997484</td>\n",
              "      <td>0.996176</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998084</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.054100</td>\n",
              "      <td>0.038094</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.996146</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.992512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.042700</td>\n",
              "      <td>0.030602</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.998066</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.994220</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.993377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.031435</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.998069</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.995188</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.032200</td>\n",
              "      <td>0.043940</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>0.996169</td>\n",
              "      <td>0.998081</td>\n",
              "      <td>0.997124</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.998081</td>\n",
              "      <td>0.995391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.016400</td>\n",
              "      <td>0.030313</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.998069</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.995188</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.029160</td>\n",
              "      <td>0.994969</td>\n",
              "      <td>0.998073</td>\n",
              "      <td>0.994242</td>\n",
              "      <td>0.996154</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.994242</td>\n",
              "      <td>0.995296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.020200</td>\n",
              "      <td>0.025154</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>0.998077</td>\n",
              "      <td>0.996161</td>\n",
              "      <td>0.997118</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.996161</td>\n",
              "      <td>0.996256</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/checkpoint-1160/pytorch_model.bin'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-209-4a49b376ae57>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting fine-tuning...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2673\u001b[0m                 \u001b[0msmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m         \u001b[0;31m# add remaining tr_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_load_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3005\u001b[0m                         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafetensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_safe_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m                         state_dict = torch.load(\n\u001b[0m\u001b[1;32m   3008\u001b[0m                             \u001b[0mbest_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m                             \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/checkpoint-1160/pytorch_model.bin'"
          ]
        }
      ],
      "source": [
        "print(\"\\nStarting fine-tuning...\")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjjf1_kICj0H"
      },
      "source": [
        "## Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "D9FRpt91Crqn",
        "outputId": "3aa513b5-8ca3-46ed-baf0-88f7cb327ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating model on test set...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2321' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2320/2320 21:35, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Human Accuracy</th>\n",
              "      <th>Human False Positive Rate</th>\n",
              "      <th>Ai Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.074109</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.996146</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.992512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.117700</td>\n",
              "      <td>0.083082</td>\n",
              "      <td>0.991195</td>\n",
              "      <td>0.996139</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.993263</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.991552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.075300</td>\n",
              "      <td>0.049584</td>\n",
              "      <td>0.997484</td>\n",
              "      <td>0.996176</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998084</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.054100</td>\n",
              "      <td>0.038094</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.996146</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.992512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.042700</td>\n",
              "      <td>0.030602</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.998066</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.994220</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.993377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.031435</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.998069</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.995188</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.032200</td>\n",
              "      <td>0.043940</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>0.996169</td>\n",
              "      <td>0.998081</td>\n",
              "      <td>0.997124</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.998081</td>\n",
              "      <td>0.995391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.016400</td>\n",
              "      <td>0.030313</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.998069</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.995188</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.029160</td>\n",
              "      <td>0.994969</td>\n",
              "      <td>0.998073</td>\n",
              "      <td>0.994242</td>\n",
              "      <td>0.996154</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.994242</td>\n",
              "      <td>0.995296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.020200</td>\n",
              "      <td>0.039305</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.996183</td>\n",
              "      <td>0.994286</td>\n",
              "      <td>0.995234</td>\n",
              "      <td>0.992593</td>\n",
              "      <td>0.007407</td>\n",
              "      <td>0.994286</td>\n",
              "      <td>0.993439</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test results: {'eval_loss': 0.03930509462952614, 'eval_accuracy': 0.9937106918238994, 'eval_precision': 0.9961832061068703, 'eval_recall': 0.9942857142857143, 'eval_f1': 0.9952335557673975, 'eval_human_accuracy': 0.9925925925925926, 'eval_human_false_positive_rate': 0.007407407407407408, 'eval_ai_accuracy': 0.9942857142857143, 'eval_balanced_accuracy': 0.9934391534391535}\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nEvaluating model on test set...\")\n",
        "test_results = trainer.evaluate(tokenized_test)\n",
        "print(f\"Test results: {test_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtHLTV_NCwde",
        "outputId": "271982e6-5a9d-466a-a49b-03ee6e5448c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/vocab.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/merges.txt',\n",
              " '/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/added_tokens.json',\n",
              " '/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results/roberta-lora-raid-abstracts/tokenizer.json')"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Save the fine-tuned model\n",
        "save_dir = \"/content/drive/MyDrive/Colab Notebooks/LLMs_project/TuringLens/results\"\n",
        "model_name = \"roberta-lora-raid-abstracts\"\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "model.save_pretrained(f\"{save_dir}/{model_name}\")\n",
        "tokenizer.save_pretrained(f\"{save_dir}/{model_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GLY5b4AC9-t"
      },
      "outputs": [],
      "source": [
        "def predict_on_dataset(dataset):\n",
        "    outputs = trainer.predict(dataset)\n",
        "    predictions = np.argmax(outputs.predictions, axis=1)\n",
        "    true_labels = outputs.label_ids\n",
        "    return predictions, true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "UmPmNzqvDASa",
        "outputId": "834139cd-3942-4a94-d6c7-63fe2d674693"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2321' max='2320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2320/2320 21:35, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Human Accuracy</th>\n",
              "      <th>Human False Positive Rate</th>\n",
              "      <th>Ai Accuracy</th>\n",
              "      <th>Balanced Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.074109</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.996146</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.992512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.117700</td>\n",
              "      <td>0.083082</td>\n",
              "      <td>0.991195</td>\n",
              "      <td>0.996139</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.993263</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.991552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.075300</td>\n",
              "      <td>0.049584</td>\n",
              "      <td>0.997484</td>\n",
              "      <td>0.996176</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998084</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.996350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.054100</td>\n",
              "      <td>0.038094</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.996146</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.992512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.042700</td>\n",
              "      <td>0.030602</td>\n",
              "      <td>0.992453</td>\n",
              "      <td>0.998066</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.994220</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.990403</td>\n",
              "      <td>0.993377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.033100</td>\n",
              "      <td>0.031435</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.998069</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.995188</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.032200</td>\n",
              "      <td>0.043940</td>\n",
              "      <td>0.996226</td>\n",
              "      <td>0.996169</td>\n",
              "      <td>0.998081</td>\n",
              "      <td>0.997124</td>\n",
              "      <td>0.992701</td>\n",
              "      <td>0.007299</td>\n",
              "      <td>0.998081</td>\n",
              "      <td>0.995391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.016400</td>\n",
              "      <td>0.030313</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.998069</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.995188</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.992322</td>\n",
              "      <td>0.994336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.029160</td>\n",
              "      <td>0.994969</td>\n",
              "      <td>0.998073</td>\n",
              "      <td>0.994242</td>\n",
              "      <td>0.996154</td>\n",
              "      <td>0.996350</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.994242</td>\n",
              "      <td>0.995296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.020200</td>\n",
              "      <td>0.039305</td>\n",
              "      <td>0.993711</td>\n",
              "      <td>0.996183</td>\n",
              "      <td>0.994286</td>\n",
              "      <td>0.995234</td>\n",
              "      <td>0.992593</td>\n",
              "      <td>0.007407</td>\n",
              "      <td>0.994286</td>\n",
              "      <td>0.993439</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 00:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "test_preds, test_labels = predict_on_dataset(tokenized_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zF2cXJlYDA3r",
        "outputId": "ad594903-c434-4154-beef-b5d62505d389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Detailed Test Results:\n",
            "accuracy: 0.9937\n",
            "precision: 0.9962\n",
            "recall: 0.9943\n",
            "f1: 0.9952\n"
          ]
        }
      ],
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(test_labels, test_preds)\n",
        "precision = precision_score(test_labels, test_preds)\n",
        "recall = recall_score(test_labels, test_preds)\n",
        "f1 = f1_score(test_labels, test_preds)\n",
        "\n",
        "print(\"\\nDetailed Test Results:\")\n",
        "print(f\"accuracy: {accuracy:.4f}\")\n",
        "print(f\"precision: {precision:.4f}\")\n",
        "print(f\"recall: {recall:.4f}\")\n",
        "print(f\"f1: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "vvHdw3pKDIT_",
        "outputId": "a458b3f5-4d4f-4f2e-801d-f9165a3ea057"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[\"Human\", \"AI\"], yticklabels=[\"Human\", \"AI\"])\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.title('Confusion Matrix (Test Set)')\n",
        "plt.savefig(f\"{save_dir}/{model_name}_confusion_matrix.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tJ31Dx0DJRh",
        "outputId": "70a3d5c6-7342-4f9c-ee2c-0c4310904a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Results:\n",
            "   Class  Correct Predictions  Misclassifications\n",
            "0  Human                  268                   2\n",
            "1     AI                  522                   3\n"
          ]
        }
      ],
      "source": [
        "# Extract confusion matrix values for a results table\n",
        "correct_human = cm[0][0]  # True negative\n",
        "incorrect_human = cm[0][1]  # False positive\n",
        "correct_ai = cm[1][1]  # True positive\n",
        "incorrect_ai = cm[1][0]  # False negative\n",
        "\n",
        "# Create a results table similar to the one shown\n",
        "results_table = pd.DataFrame({\n",
        "    \"Class\": [\"Human\", \"AI\"],\n",
        "    \"Correct Predictions\": [correct_human, correct_ai],\n",
        "    \"Misclassifications\": [incorrect_human, incorrect_ai]\n",
        "})\n",
        "\n",
        "print(\"\\nClassification Results:\")\n",
        "print(results_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5ltZcI5DPVL",
        "outputId": "ee7ff1dc-ca15-403a-87cc-43fa1169431f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Human Detection Accuracy: 0.9926\n",
            "AI Detection Accuracy: 0.9943\n",
            "Overall Accuracy: 0.9937\n",
            "\n",
            "Performance by Model Type:\n",
            "              accuracy  count\n",
            "gpt3          1.000000     33\n",
            "cohere        1.000000     35\n",
            "gpt2          1.000000     64\n",
            "chatgpt       1.000000     32\n",
            "gpt4          1.000000     26\n",
            "cohere-chat   1.000000     40\n",
            "mistral-chat  1.000000     54\n",
            "mpt-chat      1.000000     73\n",
            "llama-chat    1.000000     58\n",
            "human         0.992593    270\n",
            "mistral       0.981818     55\n",
            "mpt           0.963636     55\n"
          ]
        }
      ],
      "source": [
        "# Calculate class-specific accuracy metrics\n",
        "human_accuracy = correct_human / (correct_human + incorrect_human)\n",
        "ai_accuracy = correct_ai / (correct_ai + incorrect_ai)\n",
        "overall_accuracy = (correct_human + correct_ai) / (correct_human + correct_ai + incorrect_human + incorrect_ai)\n",
        "\n",
        "print(f\"\\nHuman Detection Accuracy: {human_accuracy:.4f}\")\n",
        "print(f\"AI Detection Accuracy: {ai_accuracy:.4f}\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
        "\n",
        "# Analyze performance by model type\n",
        "print(\"\\nPerformance by Model Type:\")\n",
        "model_performance = {}\n",
        "\n",
        "# Create test_df with predictions\n",
        "test_df_with_preds = test_df.copy()\n",
        "test_df_with_preds['prediction'] = test_preds\n",
        "\n",
        "# Calculate accuracy for each model type\n",
        "for model_name in test_df_with_preds['model'].unique():\n",
        "    model_df = test_df_with_preds[test_df_with_preds['model'] == model_name]\n",
        "    model_acc = accuracy_score(model_df['label'], model_df['prediction'])\n",
        "    model_count = len(model_df)\n",
        "    model_performance[model_name] = {\"accuracy\": model_acc, \"count\": model_count}\n",
        "\n",
        "# Convert to DataFrame for nice display\n",
        "model_df = pd.DataFrame.from_dict(model_performance, orient='index')\n",
        "model_df = model_df.sort_values(\"accuracy\", ascending=False)\n",
        "print(model_df)\n",
        "\n",
        "# Save training logs\n",
        "training_logs = pd.DataFrame(trainer.state.log_history)\n",
        "training_logs.to_csv(f\"{save_dir}/{model_name}_training_log.csv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uegT4d960qUw"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Human Detection Accuracy: 99.26% (up from ~16.8% originally)\n",
        "*   AI Detection Accuracy: 99.43% (maintained from ~97.3% originally)\n",
        "*   Human False Positive Rate: 0.74% - Only 2 out of 270 human texts misclassified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F23nNj-p1t4F"
      },
      "source": [
        "Citation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4y2uy0S1RNe"
      },
      "outputs": [],
      "source": [
        "@inproceedings{dugan-etal-2024-raid,\n",
        "    title = \"{RAID}: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors\",\n",
        "    author = \"Dugan, Liam  and\n",
        "      Hwang, Alyssa  and\n",
        "      Trhl{\\'\\i}k, Filip  and\n",
        "      Zhu, Andrew  and\n",
        "      Ludan, Josh Magnus  and\n",
        "      Xu, Hainiu  and\n",
        "      Ippolito, Daphne  and\n",
        "      Callison-Burch, Chris\",\n",
        "    booktitle = \"Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n",
        "    month = aug,\n",
        "    year = \"2024\",\n",
        "    address = \"Bangkok, Thailand\",\n",
        "    publisher = \"Association for Computational Linguistics\",\n",
        "    url = \"https://aclanthology.org/2024.acl-long.674\",\n",
        "    pages = \"12463--12492\",\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}